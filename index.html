<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.427">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="keywords" content="Computational Science, Publication, Reproducibility, Workflows">

<title>LivePublication</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="index_files/libs/quarto-contrib/social-share-0.1.0/social-share.css" rel="stylesheet">
<link href="index_files/libs/quarto-contrib/social-share-0.1.0/all.css" rel="stylesheet">


<link rel="stylesheet" href="styles.css">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><p>LivePublication</p></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead"></p><p>The science workflow creates and updates the publication</p><p></p>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-heading">Affiliations</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Augustus Ellerm <a href="https://orcid.org/0000-1111-2222-3333" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Canterbury, Christchurch, New Zealand
            </p>
        </div>
        <div class="quarto-title-meta-contents">
      <p class="author">Mark Gahegan <a href="https://orcid.org/0000-3333-2222-1111" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Auckland, Auckland, New Zealand
            </p>
        </div>
        <div class="quarto-title-meta-contents">
      <p class="author">Benjamin Adams <a href="https://orcid.org/0000-2222-1111-3333" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              University of Canterbury, Christchurch, New Zealand
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">7/4/23</p>
      </div>
    </div>
    
      
    </div>
    
  <div>
    <div class="abstract">
      <div class="abstract-title">Abstract</div>
      <p>The uptake of computational methods to support research has led to some remarkable new tools and methods to improve outcomes. But one unintended consequence is that the scientific record ends up being fragmented and distributed amongst several distinct systems. The research we report aims to gather together of the components of an experiment into a single container—including the publication itself. We describe the architecture of such a system that marries together distributed workflows (Globus) with research object containers (RO-Crate) and adds new methods to describe, update and `publish’ the details of the workflow and its outcomes. Finally, we demonstrate the system with a natural language processing research use case.</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul class="collapse">
  <li><a href="#sec-introduction" id="toc-sec-introduction" class="nav-link active" data-scroll-target="#sec-introduction">Introduction</a></li>
  <li><a href="#sec-background" id="toc-sec-background" class="nav-link" data-scroll-target="#sec-background">Background</a></li>
  <li><a href="#sec-LP_framework" id="toc-sec-LP_framework" class="nav-link" data-scroll-target="#sec-LP_framework">LivePublication Framework</a>
  <ul class="collapse">
  <li><a href="#sec-LP_architecture" id="toc-sec-LP_architecture" class="nav-link" data-scroll-target="#sec-LP_architecture">LivePublication architecture</a></li>
  </ul></li>
  <li><a href="#sec-Implementing_LP" id="toc-sec-Implementing_LP" class="nav-link" data-scroll-target="#sec-Implementing_LP">Implementing LivePublication</a>
  <ul class="collapse">
  <li><a href="#l1-cloud-computing" id="toc-l1-cloud-computing" class="nav-link" data-scroll-target="#l1-cloud-computing">L1: Cloud computing</a></li>
  <li><a href="#sec-workflow_platforms" id="toc-sec-workflow_platforms" class="nav-link" data-scroll-target="#sec-workflow_platforms">L2: Workflow orchestration and artefact generation</a></li>
  <li><a href="#l3-publication---presentation-and-integration" id="toc-l3-publication---presentation-and-integration" class="nav-link" data-scroll-target="#l3-publication---presentation-and-integration">L3: Publication - presentation and integration</a></li>
  </ul></li>
  <li><a href="#sec-case_study" id="toc-sec-case_study" class="nav-link" data-scroll-target="#sec-case_study">Comparative Language Identification Case Study</a></li>
  <li><a href="#sec-futurework" id="toc-sec-futurework" class="nav-link" data-scroll-target="#sec-futurework">Conclusions and Future Work</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</div>
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<section id="sec-introduction" class="level1">
<h1>Introduction</h1>
<p>The way that science is published has not changed substantially in 350 years, despite the obvious limitations of a static and incomplete account of the research performed. This is especially true for research that is ‘born digital’ where rich representations are removed in order to fit into the traditional article container literally a paper, or more recently a pdf. As the computational support of science becomes richer, the process of communicating a full and reproducible account of what was done has grown increasingly possible, but also increasingly cumbersome <span class="citation" data-cites="baker20161">[<a href="#ref-baker20161" role="doc-biblioref">2</a>]</span>. To address this the FAIR principles call for co-publication of code and data alongside the original research article <span class="citation" data-cites="wilkinson2016fair">[<a href="#ref-wilkinson2016fair" role="doc-biblioref">27</a>]</span>. When an article is published alongside the accompanying code and data, it significantly enhances the potential for reuse, reproducibility, and transparency of the work. However, there remain many other unrealised improvements that we seek here to create fully reproducible, explainable, and self-updating (`live’) publications, ensuring other researchers can effectively understand, validate, and build upon the work.</p>
<p>Our overall aim is to create a single container for a fully complete account of some conducted research, including data (even if remotely accessed), workflows, code, mathematics, tables and figures, and text. And then to allow artefacts to be modified in response to newer or better versions becoming available. The simplest example of this is a research article describing some dynamic phenomenon (such as the state of a pandemic or an ocean circulation model) that automatically updates itself when new data is available.</p>
<p>While supplementing traditional research articles with additional research artefacts has gained popularity, emerging research platforms are offering innovative ways to capture and communicate a scientist’s workflow more fully. Platforms like Galaxy <span class="citation" data-cites="jalili2020galaxy">[<a href="#ref-jalili2020galaxy" role="doc-biblioref">16</a>]</span> and Physiome <span class="citation" data-cites="nickerson2017introducing">[<a href="#ref-nickerson2017introducing" role="doc-biblioref">21</a>]</span> facilitate the publication of computational workflows, models, and tools, while also offering remote execution services that promote the development of virtual laboratories and foster collaboration. Meanwhile, software tools such as Jupyter Notebooks <span class="citation" data-cites="kluyver2016jupyter">[<a href="#ref-kluyver2016jupyter" role="doc-biblioref">17</a>]</span> and Stencila <span class="citation" data-cites="aufreiter2018stencila">[<a href="#ref-aufreiter2018stencila" role="doc-biblioref">1</a>]</span> combine code, data, and descriptive elements, enabling interactive sessions that provide users with hands-on experience and a deeper understanding of the methodology.</p>
<p>These two perspectives—augmentation of traditional articles and development of new publication methods—both seek to resolve the gap between research performed and research communicated. Publication platforms that integrate executable code, data, and descriptive elements address foundational issues such as reproducibility, reuse, and transparency. Furthermore, they unlock the potential for innovative changes, such as creating dynamic research articles that respond to changes in their originating workflows, even once they have been published.</p>
<p>This paper introduces a novel framework called <em>LivePublication</em> that seamlessly integrates highly distributed computational workflows, data, and descriptive elements. Its primary goal is to deliver dynamic, live research articles that accurately reflect the current state of the computational pipeline, thereby providing a more interactive and up-to-date representation of the research process. In fields where constant surveillance or regular data and algorithm improvements are common—e.g., environmental science and pandemic monitoring—much published research is out of date even before it appears in print. This leads to huge inefficiencies and reliability issues, and new publications that only serve to update the data or methods. Integrating research articles with <em>distributed</em> computational workflows is an essential intricacy, as complex computational workflows often demand scalability, portability, and compartmentalisation of components. Distributed computational environments also offer potential for novel extensibility use cases and can foster enhanced communication and understanding of the underlying scientific methodology.</p>
<p>After reviewing related work on co-publication, executable articles, workflow platforms, and virtual laboratories in next section, the required attributes of the LivePublication framework are introduced in <a href="#sec-LP_framework">Section&nbsp;3</a>. Following that, in <a href="#sec-Implementing_LP">Section&nbsp;4</a> we describe an instantiation of LivePublication that satisfies these requirements, leveraging prior work on Globus and the RO-Crate method. In <a href="#sec-case_study">Section&nbsp;5</a> we demonstrate the utility of this approach with a natural language processing case study. Finally, we end with our vision for LivePublication going forward and plans for future work.</p>
</section>
<section id="sec-background" class="level1">
<h1>Background</h1>
<p>The reproducibility crisis <span class="citation" data-cites="baker2016reproducibility">[<a href="#ref-baker2016reproducibility" role="doc-biblioref">3</a>]</span> has led to a call for more transparent, repeatable, and verifiable research. The FAIR principles (Findable, Accessible, Interoperable, and Reusable), developed by Wilkinson et al. <span class="citation" data-cites="wilkinson2016fair">[<a href="#ref-wilkinson2016fair" role="doc-biblioref">27</a>]</span>, provide guidelines for enhancing the reproducibility and transparency of research data and methods. Co-publication, where code, data, and external resources are published alongside traditional articles is one solution. This approach has been adopted widely, e.g., <a href="https://portal.paperswithcode.com/">Papers with Code</a>, <a href="https://zenodo.org">Zenodo</a>, and Research Compendium <span class="citation" data-cites="stodden2015researchcompendia">[<a href="#ref-stodden2015researchcompendia" role="doc-biblioref">23</a>]</span>. This mode of publication enables reproduction and reuse, reducing inefficiencies in research processes.</p>
<p>In contrast to co-publication, ‘executable articles’ combine data, methods, and natural language content to create interactive documents that can be re-executed to reproduce original results or generate new insights <span class="citation" data-cites="lasser2020creating">[<a href="#ref-lasser2020creating" role="doc-biblioref">18</a>]</span>. Tools such as Jupyter Notebooks <span class="citation" data-cites="kluyver2016jupyter">[<a href="#ref-kluyver2016jupyter" role="doc-biblioref">17</a>]</span>, Google Colaboratory <span class="citation" data-cites="bisong2019google">[<a href="#ref-bisong2019google" role="doc-biblioref">5</a>]</span>, and Stencila <span class="citation" data-cites="aufreiter2018stencila">[<a href="#ref-aufreiter2018stencila" role="doc-biblioref">1</a>]</span> interweave text with code cells to facilitate step-by-step, reproducible computations. In a slightly different approach, solutions like Paper Mâché <span class="citation" data-cites="brammer2011paper">[<a href="#ref-brammer2011paper" role="doc-biblioref">6</a>]</span>, Executable Paper <span class="citation" data-cites="strijkers2011toward">[<a href="#ref-strijkers2011toward" role="doc-biblioref">24</a>]</span>, and Ghosh et al.’s neuroimaging re-executable publication <span class="citation" data-cites="ghosh2017very">[<a href="#ref-ghosh2017very" role="doc-biblioref">13</a>]</span> separate the code and data from narrative text, providing a traditional article with re-execution capabilities. Our own previous effort <span class="citation" data-cites="ellerm2022enabling">[<a href="#ref-ellerm2022enabling" role="doc-biblioref">11</a>]</span> integrates workflows and natural language text by combining Common Workflow Language (CWL) descriptions, execution capabilities, and author-written content on a central server.</p>
<p>The bioinformatics and biomedical communities in particular have developed many domain-specific workflow platforms. For example, Galaxy and Anduil 2 <span class="citation" data-cites="jalili2020galaxy cervera2019anduril">[<a href="#ref-cervera2019anduril" role="doc-biblioref">8</a>, <a href="#ref-jalili2020galaxy" role="doc-biblioref">16</a>]</span> provide workflow capabilities and thus code abstraction and reuse of computational components. General workflow frameworks like Pegasus, CWL, and AiiDA <span class="citation" data-cites="deelman2015pegasus crusoe2022methods huber2020aiida">[<a href="#ref-crusoe2022methods" role="doc-biblioref">9</a>, <a href="#ref-deelman2015pegasus" role="doc-biblioref">10</a>, <a href="#ref-huber2020aiida" role="doc-biblioref">15</a>]</span> are geared towards providing universal solutions, with mechanisms to customise and develop bespoke workflows to meet diverse research needs. In industry, Amazon and Google both provide workflow platforms for cloud infrastructure. Workflow technologies provide some abstraction for complex, reusable scientific methodologies. It is this abstraction that serves as an interface for building and exporting artefacts, ready for integration into a publication medium (as described in <a href="#sec-LP_architecture">Section&nbsp;3.1</a>).</p>
<p>Virtual laboratories and scientific gateways abstract the complexity of underlying computational infrastructure, offering scientists an accessible and intuitive interface for conducting research. <a href="https://codeocean.com">Code Ocean</a>, HubZero <span class="citation" data-cites="mclennan2010hubzero">[<a href="#ref-mclennan2010hubzero" role="doc-biblioref">19</a>]</span>, and CIPRES <span class="citation" data-cites="miller2011cipres">[<a href="#ref-miller2011cipres" role="doc-biblioref">20</a>]</span> offer tools for domain specific data management, analysis, and visualisation. MyExperiment and Wholetale <span class="citation" data-cites="goble2010myexperiment brinckman2019computing">[<a href="#ref-brinckman2019computing" role="doc-biblioref">7</a>, <a href="#ref-goble2010myexperiment" role="doc-biblioref">14</a>]</span> are examples of virtual laboratories, serving as collaborative environments where researchers can create, share, and execute scientific workflows.</p>
<p>LivePublication extends the capabilities of these platforms by directly interfacing with live workflow platforms and generating article-like outputs. This moves us towards a more dynamic, interactive, and up-to-date representation of research.</p>
</section>
<section id="sec-LP_framework" class="level1">
<h1>LivePublication Framework</h1>
<p>The design of LivePublication reflects the need to satisfy a dual set of functional requirements: those of computational workflows and of the publication process. Prior solutions to overcome gaps in publication often overlook the role of complex computational pipelines in science. Therefore, the LivePublication framework is designed to exhibit six key attributes:</p>
<ol type="1">
<li><strong>Liveness</strong>: live links to all the computational resources used in a workflow, so that it can be responsive to changes (such as new data);</li>
<li><strong>Reproducibility</strong>: replication of the same results / conclusions given the computational method and data;</li>
<li><strong>Reusability/Extensibility</strong>: reuse of, or extension of, the computational pipeline components;</li>
<li><strong>Transparency</strong>: the ability to inspect the computational pipeline, with tools to automatically derive text descriptions of workflow and code;</li>
<li><strong>Distribution</strong>: support for complex, distributed computational pipelines and data repositories;</li>
<li><strong>Completeness</strong>: The methods, data, workflow, results, and findings are held within a single container, with their inter-dependencies intact.</li>
</ol>
<p>The concept of ‘reproducibility’ is best defined by The Turing Way <span class="citation" data-cites="Way_Community_The_Turing2019-qd">[<a href="#ref-Way_Community_The_Turing2019-qd" role="doc-biblioref">25</a>]</span>, which delineates reproducibility into four distinct categories based on analysis and data: Reproducible, Replicable, Robust, and Generalizable. We adopt these definitions for clarity and precision in discussing LivePublication. A fundamental requirement of a LivePublication instance is reproducibility, as each LivePublication is generated through the periodic re-execution of its underlying computational pipeline. Depending on the extensibility and reusability of a given instance, as supported by its underlying infrastructure, it can also meet the conditions for being replicable and robust.</p>
<p>Reusability, within the LivePublication framework, refers to the ability of methods—both computational and broader scientific methodologies—to be reused by a third party. At its simplest, the inclusion of static code within the publication can satisfy the basic reusability criteria established by many journals. The LivePublication computational pipeline can enable more dynamic forms of reuse. For instance, where portions of the computational workflow can be repurposed and incorporated by external parties, emulating the code execution behaviour seen in tools like Jupyter notebooks <span class="citation" data-cites="kluyver2016jupyter">[<a href="#ref-kluyver2016jupyter" role="doc-biblioref">17</a>]</span>.</p>
<p>Transparency in LivePublication extends beyond simple code availability. It encapsulates the clarity of the methodology: its communication and the precision of that communication. A transparent method provides tools that enable users to understand the process in question and make informed value judgements about its application. LivePublication facilitates more comprehensive descriptions via computational methods to automatically generate various levels of text description of both code and workflow.</p>
<p>Distribution is addressed via scalability and data locality. Beyond these pragmatic concerns, distributed pipelines offer significant value in terms of their inherent modular structure. By compartmentalising methods into granular computational units, we enhance both reusability and extensibility. Finally, completeness is achieved by bringing all aspects of a science experiment, from the data to the resulting publication, into a single container.</p>
<section id="sec-LP_architecture" class="level2">
<h2 class="anchored" data-anchor-id="sec-LP_architecture">LivePublication architecture</h2>
<p>An overview of the LivePublication technology stack is provided in <a href="#fig-highlevel_architecture">Figure&nbsp;1</a> and shows the three conceptual levels of the architecture.</p>
<div id="fig-highlevel_architecture" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/Highlevel-architecture.png" class="img-fluid figure-img" style="width:75.0%" alt="LivePublication architecture outline"></p>
<figcaption class="figure-caption">Figure&nbsp;1: High-level LivePublication architecture</figcaption>
</figure>
</div>
<p>The foundation <em>Layer 1</em>, denoted as <em>Hardware / Infrastructure / Aggregate Systems</em>, encompasses the essential technology necessary for the distributed computational workflow. This can include a myriad of components, from virtual machines and scientific instruments (like sensors and speciality hardware) to data stores and other enabling technologies. Despite the potential diversity in form, each component must meet certain prerequisites to participate within a distributed workflow—namely, they must be accessible and actionable by a workflow management system.</p>
<p>Moving up to <em>Level 2</em>, two concurrent components are presented representing a primary innovation of the LivePublication framework. Sitting upon the hardware layer, the Workflow and Data Management systems orchestrate the computational process. Development efforts are actively underway for tools that manage workflow execution. Galaxy <span class="citation" data-cites="jalili2020galaxy">[<a href="#ref-jalili2020galaxy" role="doc-biblioref">16</a>]</span>, Globus <span class="citation" data-cites="foster1998globus">[<a href="#ref-foster1998globus" role="doc-biblioref">12</a>]</span>, Pegasus <span class="citation" data-cites="deelman2015pegasus">[<a href="#ref-deelman2015pegasus" role="doc-biblioref">10</a>]</span>, and CWL <span class="citation" data-cites="crusoe2022methods">[<a href="#ref-crusoe2022methods" role="doc-biblioref">9</a>]</span> represent a handful of well-known workflow management tools, each with its unique focus and priorities. For the LivePublication context, tools that emphasise robust data management techniques, such as data locality, efficient data transfer at scale, and cross-boundary data transfer, are particularly advantageous. These tools align well with the functional requirements of today’s researchers and can effectively facilitate the creation of a LivePublication.</p>
<p>LivePublication Artefact Generation occurs concurrently, and agnostically, of workflow execution. Essentially, each step or computational unit generates a descriptive artefact, documenting its execution and the ensuing results. This critical process forms the cornerstone of integrating workflow executions with publication media, offering a mechanism for distilling information from multiple computational steps and preserving their outputs for subsequent processing. By maintaining a clear and detailed record of each step of the scientific process (not just those steps conducted locally), it not only enhances transparency but also greatly facilitates reproducibility and extensibility.</p>
<p>Finally, <em>Level 3 – Publication: Presentation and Integration</em> serves as the integration point for LivePublication artefacts, synthesising the outputs of the executed workflow into a cohesive, comprehensive account. This includes the results of the computational process like figures and resultant data, as well as the publication artefacts generated during the workflow execution. Beyond these, it can incorporate additional information such as workflow definition, versioning details, and other supplementary information, providing a rich, detailed snapshot of the entire scientific process.</p>
</section>
</section>
<section id="sec-Implementing_LP" class="level1 page-columns page-full">
<h1>Implementing LivePublication</h1>
<p>This section discusses the specific technologies that have been chosen to actualise LivePublication, showing how integration between distributed workflows and publications can be achieved. In particular, we highlight how these technologies facilitate seamless information integration between distributed workflows and the subsequent publication process.</p>
<section id="l1-cloud-computing" class="level2">
<h2 class="anchored" data-anchor-id="l1-cloud-computing">L1: Cloud computing</h2>
<p>Cloud computing services are a natural choice for implementing <em>Layer 1</em> due to their scalability and flexibility, accommodating the variable computational and data storage needs inherent in scientific workflows. Our initial implementation of LivePublication uses the <a href="www.nectar.org.au">Nectar Research Cloud</a>, an OpenStack-based cloud computing platform, due to its availability, flexibility, and control that OpenStack provides over the deployed infrastructure. These qualities directly align with the LivePublication design objectives, particularly in terms of extensibility and distributed computing, as they allow for customisation and seamless integration with various computational workflows. OpenStack’s open-source nature further facilitates this by encouraging collaboration and customisation, making it a fitting choice for LivePublication.</p>
</section>
<section id="sec-workflow_platforms" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-workflow_platforms">L2: Workflow orchestration and artefact generation</h2>
<section id="workflow-orchestration" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="workflow-orchestration">Workflow orchestration</h3>
<p>Transitioning to <em>Layer 2</em>, we turn our focus to workflow management. The choice of workflow platform is a significant decision, as LivePublication relies on the close integration of workflow execution and artefact generation. LivePublication requires access to each computational step in a workflow’s execution, providing an interface to generate and export a descriptive artefact (<em>LP Artefact</em>) for later processing. So the workflow platform must be open source, and support custom behaviours and plugins. While several workflow platforms do offer means to implement custom workflow steps <span class="citation" data-cites="crusoe2022methods huber2020aiida jalili2020galaxy">[<a href="#ref-crusoe2022methods" role="doc-biblioref">9</a>, <a href="#ref-huber2020aiida" role="doc-biblioref">15</a>, <a href="#ref-jalili2020galaxy" role="doc-biblioref">16</a>]</span>, we here take the view that outcomes of a step (LP Artefacts) are better represented as external to the step itself, as generalised pre/post processing for a custom LivePublication class of workflow.</p>
<p>A custom Globus AP template has been developed to support the integration of LivePublication with Globus flows. The template is a simple Flask REST server, providing the base functionality to integrate with the Globus-Auth service and enabling LivePublication artefact generation (covered in the next section). Each LivePublication Action Provider (LPAP) is extended in three important ways:</p>
<ul>
<li><strong>Containerisation</strong>: Packaging the computational method as a Docker container;</li>
<li><strong>Artefact Generation</strong>: Functionality to generate LP artefacts and integrate metadata;</li>
<li><strong>Artefact Transfer</strong>: Automating reliable transfer of generated LP artefacts for subsequent processing.</li>
</ul>
<p>Each LPAP contains a Docker image of the computational method it executes as its service. Packaging the method in this way provides four primary advantages: environment management, reuse and inclusion, parallelisation, and AP maintenance.</p>
<section id="containerisation" class="level4">
<h4 class="anchored" data-anchor-id="containerisation">Containerisation</h4>
<p>Abstracting the execution environment from the server environment is required as many computational methods rely on specific dependencies and configurations for their execution. Docker images are integrated with LPAPs through a mirrored directory structure shared between the image and server. LPAPs include <em>input</em> and <em>output</em> directories which map to directories of the same name within the docker container. This allows incoming data to be ingested, and processed data to be exported, between the container and servers contexts. Further, these standard directories enable the inclusion of both incoming data and processed data within LP Artefacts.</p>
<p>Containerisation enables us to bundle the computational method within an LP artefact. Moreover, containers are capable of handling numerous incoming action requests simultaneously, scaling well. Lastly, containerisation fosters an agile development environment and simplifies the maintenance of the AP’s method. By encapsulating each service within its container, modifications can be made without disrupting the entire system, contributing to a more resilient and manageable system overall.</p>
</section>
<section id="sec-artefact_generation" class="level4">
<h4 class="anchored" data-anchor-id="sec-artefact_generation">Artefact generation</h4>
<p>For the generation of LP artefacts, we have developed an open-source Python library <code>lp_ap_tools</code>. A Python decorator (<a href="#lst-lp_ap_tools">Listing&nbsp;1</a>) encapsulates the execution of the computational method’s Docker container within the LPAP. By wrapping the executed method in this decorator, metadata mining and information gathering can be performed both pre- and post-execution.</p>
<div id="lst-lp_ap_tools" class="listing">
<p>Listing&nbsp;1: LP_artefact decorator</p>
<div class="sourceCode" id="lst-lp_ap_tools" data-lst-cap="LP_artefact decorator"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-lp_ap_tools-1"><a href="#lst-lp_ap_tools-1" aria-hidden="true" tabindex="-1"></a><span class="at">@LP_artefact</span>(dir_struct<span class="op">=</span>directory_structure)</span>
<span id="lst-lp_ap_tools-2"><a href="#lst-lp_ap_tools-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> run_computation(<span class="op">**</span>arguments):</span>
<span id="lst-lp_ap_tools-3"><a href="#lst-lp_ap_tools-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Execute method container</span></span>
<span id="lst-lp_ap_tools-4"><a href="#lst-lp_ap_tools-4" aria-hidden="true" tabindex="-1"></a>  container <span class="op">=</span> client.containers.run(</span>
<span id="lst-lp_ap_tools-5"><a href="#lst-lp_ap_tools-5" aria-hidden="true" tabindex="-1"></a>  image<span class="op">=</span><span class="st">'computation_image:latest'</span>,</span>
<span id="lst-lp_ap_tools-6"><a href="#lst-lp_ap_tools-6" aria-hidden="true" tabindex="-1"></a>    volumes<span class="op">=</span>volumes,</span>
<span id="lst-lp_ap_tools-7"><a href="#lst-lp_ap_tools-7" aria-hidden="true" tabindex="-1"></a>    detach<span class="op">=</span><span class="va">True</span></span>
<span id="lst-lp_ap_tools-8"><a href="#lst-lp_ap_tools-8" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pre-execution information and metadata draws on three primary sources: the LPAP, Globus services, and the server’s operating system. Each LPAP is equipped with descriptive fields, for example name, description, and keywords, which are integrated into the LivePublication artefacts. Additionally, the <code>lp_ap_tools</code> library provides a means for customising and incorporating LivePublication-specific fields into the AP’s parameters dynamically, enriching the scope of data included in LivePublication artefacts. For example, a <code>user_comment</code> field can be integrated into both REST parameters and LivePublication artefacts automatically. Further, the inclusion of source code and execution environment information is made possible by the incorporation of docker build files and respective code. Globus services, such as Globus-Auth, can be utilised to gather relevant details about the user, e.g.&nbsp;name and affiliation, and finally a full description of the hardware and configuration details of the AP can be retrieved from the server.</p>
<p>During the execution of the method, measurements can be taken, for example, execution time and resource utilisation. Currently, there is no system in place for interfacing and exporting measurements from inside the method’s container, however this possibility provides a further avenue for exporting descriptive metadata. Post-execution information and metadata primarily consists of the computational results: data, figures, and/or text which is included within the artefact.</p>
</section>
<section id="artefact-transfer" class="level4">
<h4 class="anchored" data-anchor-id="artefact-transfer">Artefact transfer</h4>
<p>Upon completing a flow consisting of LPAPs, each AP is responsible for transferring their corresponding artefacts to a designated orachestration node for collation and further processing. This is achieved by including a <code>orchestration_node_id</code> parameter in each LPAP, which is expected to contain a Globus endpoint ID. The LPAPs are configured to request permissions for the Globus transfer API, thereby granting them the authority to execute transfers on behalf of the user. Upon completion of an AP’s tasks, the LPAPs utilise the Globus transfer API to transmit their results to the assigned orchestration node.</p>
</section>
<section id="orchestration-node" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="orchestration-node">Orchestration node</h4>
<p>Given a set of LPAPs, the orchestration node manages them to form a flow. The orchestration node provides two functions:</p>
<ul>
<li><strong>Dispatches Globus flows</strong>: Initiates the execution of workflows, composed from a series of LPAPs and Globus APs;</li>
<li><strong>Collects and processes LPAP artefacts</strong>: Gathers and processes the artefacts from each LPAP</li>
</ul>
<p>The orchestration node achieves these functions using Gladier <span class="citation" data-cites="vescovi2022linking">[<a href="#ref-vescovi2022linking" role="doc-biblioref">26</a>]</span>, a Globus SDK, which enables the node to programmatically construct workflows from individual descriptions of LPAPs and Globus transfer APs. This capability allows the node to flexibly orchestrate workflows (and LivePublications), which can be adjusted as needed to suit varying use cases.</p>
<p>As an example, consider a flow that includes LPAPs <em>Process_one</em> and <em>Process_two</em>. The orchestration node generates a simple flow description as follows:</p>
<div id="lst-WEP" class="listing">
<p>Listing&nbsp;2: Generated Workflow Execution Plan</p>
<div class="sourceCode" id="lst-WEP" data-lst-cap="Generated Workflow Execution Plan"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="lst-WEP-1"><a href="#lst-WEP-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="lst-WEP-2"><a href="#lst-WEP-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"Comment"</span><span class="fu">:</span> <span class="st">"&lt;Comment&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-3"><a href="#lst-WEP-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"StartAt"</span><span class="fu">:</span> <span class="st">"Process_one"</span><span class="fu">,</span></span>
<span id="lst-WEP-4"><a href="#lst-WEP-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"States"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WEP-5"><a href="#lst-WEP-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"Process_one"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WEP-6"><a href="#lst-WEP-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ActionScope"</span><span class="fu">:</span> <span class="st">"&lt;ActionScope&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-7"><a href="#lst-WEP-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ActionUrl"</span><span class="fu">:</span> <span class="st">"&lt;ActionUrl&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-8"><a href="#lst-WEP-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"Parameters"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WEP-9"><a href="#lst-WEP-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"orchestration_node_id"</span><span class="fu">:</span> <span class="st">"&lt;orch_id&gt;"</span></span>
<span id="lst-WEP-10"><a href="#lst-WEP-10" aria-hidden="true" tabindex="-1"></a>      <span class="fu">},</span></span>
<span id="lst-WEP-11"><a href="#lst-WEP-11" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ResultPath"</span><span class="fu">:</span> <span class="st">"&lt;ResultPath&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-12"><a href="#lst-WEP-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"next"</span><span class="fu">:</span> <span class="st">"Process_two"</span></span>
<span id="lst-WEP-13"><a href="#lst-WEP-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">},</span></span>
<span id="lst-WEP-14"><a href="#lst-WEP-14" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"Process_two"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WEP-15"><a href="#lst-WEP-15" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ActionScope"</span><span class="fu">:</span> <span class="st">"&lt;ActionScope&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-16"><a href="#lst-WEP-16" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ActionUrl"</span><span class="fu">:</span> <span class="st">"&lt;ActionUrl&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-17"><a href="#lst-WEP-17" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"Parameters"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WEP-18"><a href="#lst-WEP-18" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"orchestration_node_id"</span><span class="fu">:</span> <span class="st">"&lt;orch_id&gt;"</span></span>
<span id="lst-WEP-19"><a href="#lst-WEP-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">},</span></span>
<span id="lst-WEP-20"><a href="#lst-WEP-20" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"ResultPath"</span><span class="fu">:</span> <span class="st">"&lt;ResultPath&gt;"</span><span class="fu">,</span></span>
<span id="lst-WEP-21"><a href="#lst-WEP-21" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"End"</span><span class="fu">:</span> <span class="er">True</span></span>
<span id="lst-WEP-22"><a href="#lst-WEP-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="lst-WEP-23"><a href="#lst-WEP-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="lst-WEP-24"><a href="#lst-WEP-24" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This flow description is then submitted to Globus using the users credentials. Gladier oversees the workflow’s execution, and the orchestration node simultaneously collects generated LPAP artefacts. Upon the completion of a workflow, the orchestration node gathers a description of the flow’s execution returned by Globus, and embeds this information into a unique artefact specific to the orchestration node. This artefact provides a comprehensive depiction of the Globus flow’s execution, including details about each step, its identifying parameters, and additional metadata.</p>
<p>The information held within this artefact includes but is not limited to: the action ID, the completion time, the status, and flow ID. Essentially, this artefact provides a blueprint of the execution path of the Globus flow. Here is an example of such an execution description:</p>
<div id="lst-WED" class="listing">
<p>Listing&nbsp;3: Completed Workflow Execution Description</p>
<div class="sourceCode" id="lst-WED" data-lst-cap="Completed Workflow Execution Description"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="lst-WED-1"><a href="#lst-WED-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="lst-WED-2"><a href="#lst-WED-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"action_id"</span><span class="fu">:</span> <span class="st">"&lt;action_id&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-3"><a href="#lst-WED-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"completion_time"</span><span class="fu">:</span> <span class="st">"&lt;completion_time&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-4"><a href="#lst-WED-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"display_status"</span><span class="fu">:</span> <span class="st">"&lt;display_status&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-5"><a href="#lst-WED-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"flow_id"</span><span class="fu">:</span> <span class="st">"&lt;flow_id&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-6"><a href="#lst-WED-6" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"details"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WED-7"><a href="#lst-WED-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">"output"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WED-8"><a href="#lst-WED-8" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"Process_one"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WED-9"><a href="#lst-WED-9" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"action_id"</span><span class="fu">:</span> <span class="st">"&lt;action_id&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-10"><a href="#lst-WED-10" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"completion_time"</span><span class="fu">:</span> <span class="st">"&lt;completion_time&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-11"><a href="#lst-WED-11" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"display_status"</span><span class="fu">:</span> <span class="st">"&lt;display_status&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-12"><a href="#lst-WED-12" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"details"</span><span class="fu">:</span> <span class="fu">{}</span></span>
<span id="lst-WED-13"><a href="#lst-WED-13" aria-hidden="true" tabindex="-1"></a>      <span class="fu">},</span></span>
<span id="lst-WED-14"><a href="#lst-WED-14" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"Process_two"</span><span class="fu">:</span> <span class="fu">{</span></span>
<span id="lst-WED-15"><a href="#lst-WED-15" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"action_id"</span><span class="fu">:</span> <span class="st">"&lt;action_id&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-16"><a href="#lst-WED-16" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"completion_time"</span><span class="fu">:</span> <span class="st">"&lt;completion_time&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-17"><a href="#lst-WED-17" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"display_status"</span><span class="fu">:</span> <span class="st">"&lt;display_status&gt;"</span><span class="fu">,</span></span>
<span id="lst-WED-18"><a href="#lst-WED-18" aria-hidden="true" tabindex="-1"></a>        <span class="dt">"details"</span><span class="fu">:</span> <span class="fu">{}</span></span>
<span id="lst-WED-19"><a href="#lst-WED-19" aria-hidden="true" tabindex="-1"></a>      <span class="fu">}</span></span>
<span id="lst-WED-20"><a href="#lst-WED-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="lst-WED-21"><a href="#lst-WED-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">}</span></span>
<span id="lst-WED-22"><a href="#lst-WED-22" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The orchestration node artefact is a structure integrating separate LPAP artefacts. It does so by aligning the <code>action_id</code> fields (<a href="#fig-comb_metadata">Figure&nbsp;2</a>), thereby forming a comprehensive account of the flow’s execution. This process results in a holistic description, uniting the separate elements into an interconnected narrative of the workflow’s path and outcomes.</p>
<div id="fig-comb_metadata" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/combining-metadata.png" class="img-fluid figure-img" style="width:70.0%" alt="Integrating LPAP data and Orchestration data"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Integrating LPAP artefacts</figcaption>
</figure>
</div>
<p>The result of this orchestration technique, utilising Globus APs, LPAPs, <code>lp_ap_tools</code>, and Gladier orchestration node, is a generalised method for collecting, enriching, and exporting a full description of methods used during a computational workflow, including the methods themselves. A visual overview of this process is provided in <a href="#fig-Globus_LP_artefact_gen">Figure&nbsp;3</a>. At this stage, the integrated artefact performs well as a workflow provenance and reuse / reproducibility artefact. This technology, additionally, sets the groundwork for tight integration between the execution of a computational method, and the real-time generation live, representative publications. The LPAP template is <a href="https://github.com/LivePublication/LP_GlobusAP_Template">available here</a>, demonstrating the practical implementation of custom AP services.</p>
<div class="column-body-outset">
<div id="fig-Globus_LP_artefact_gen" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/Globus-LPArtefact.png" class="img-fluid figure-img" alt="Depiction of artefact generation and orchestration using Globus Flows."></p>
<figcaption class="figure-caption">Figure&nbsp;3: Integrating artefact generation and orchestration with Globus Flows (L2 of LivePublication Architecture)</figcaption>
</figure>
</div>
</div>
</section>
</section>
<section id="ap-artefacts" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="ap-artefacts">AP Artefacts</h3>
<p>This section discusses the artefacts themselves, the technologies that enable their representation, and how they are poised to interface with <em>Layer 3</em> publications, as shown in <a href="#fig-highlevel_architecture">Figure&nbsp;1</a>. LP artefacts are dynamic objects that encapsulate data, results, and associated descriptive metadata from each computational step in a workflow. They are designed with two essential properties:</p>
<ul>
<li><strong>Self-contained and describing</strong>: Artefacts should encapsulate all the necessary information to describe the computation performed within a LPAP;</li>
<li><strong>Identifiable/Indexable</strong>: Artefacts must have consistent, unique identifiers that allow them to be accurately referenced within a publication, specifically figures, tables, and other features</li>
</ul>
<p>Each LPAP artefact contains a minimal set of data required to express the methods and results generated during its action. This must include a description of the purpose and intended application context of the LPAP, the methods used to achieve this purpose, and finally the generated results and data used. This requirement achieves two purposes. First, it ensures that each LPAP artefact is a discrete, stand-alone package of information regarding the execution of an AP, and second, it provides the minimal amount of information for methodology descriptions that can be woven into the publication.</p>
<p>The final, collated artefact must maintain consistent identifiers for use as references within the publication layer. Generated files within a flow may be inconsistent dependent on input data and flow design. To ensure consistency, LPAPs need to associate unique identifiers with their expected outputs. However there is room for further research to develop a universally applicable solution for internal identifiers, ensuring consistent reference from the point of artefact generation to publication.</p>
<p>To build artefacts that reflect these qualities, the RO-Crate specification <span class="citation" data-cites="soiland2022packaging">[<a href="#ref-soiland2022packaging" role="doc-biblioref">22</a>]</span> was selected due to its versatility, extensibility, and compatibility with diverse data types and computational workflows. Furthermore, the existence of RO-Crate SDKs simplifies its implementation, making it an approachable option for development. Notably, RO-Crates can be converted to human-readable websites, providing a user-friendly way to interface these data-rich artefacts with the publication layer.</p>
<div class="page-columns page-full"><p>RO-Crate is built around the concept of Research Objects (ROs), which align well with generated LPAP artefacts. ROs provide semantically rich, linked data, “bundling together essential information relating to experiments and investigations” . Bechhofer et al. <span class="citation" data-cites="bechhofer2013linked">[<a href="#ref-bechhofer2013linked" role="doc-biblioref">4</a>]</span> discuss how ROs enable <em>Revealable</em> (auditable) experimentation, <em>Lifecycle</em> provenance recording, and <em>Versioning</em>, which align with LivePublication’s publication layer.</p><div class="no-row-height column-margin column-container"><span class="">Why linked data is not enough for scientists <span class="citation" data-cites="bechhofer2013linked">[<a href="#ref-bechhofer2013linked" role="doc-biblioref">4</a>]</span></span></div></div>
<p>RO-Crate adds a descriptive specification grounded in <code>schema.org</code> and articulated in JSON-LD. This allows RO-Crate objects to define heterogeneous research outputs via metadata and linked data. Conceptually, RO-Crate divides possible content into two categories: <em>Data Entities</em>—e.g.&nbsp;a file or directory, and <em>Contextual Entities</em>—external information stored via metadata. RO-Crate can define links between these entities, enabling relationship modelling and creating a rich, interconnected description of research outcomes.</p>
<p>LPAP RO-Crate artefacts map a user (who executes the action within the flow) to an Action Provider (the actual provider being run) and its respective components, as depicted in <a href="#fig-LPAP_relationship_schema">Figure&nbsp;4</a> below.</p>
<div id="fig-LPAP_relationship_schema" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/ROcrate_LPAP.png" class="img-fluid figure-img" style="width:60.0%" alt="LPAP RO-Crate relationship representation"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Integrating LPAP artefacts</figcaption>
</figure>
</div>
<p>These individual LPAP RO-Crate artefacts are incorporated into the orchestration artefact via the orchestration node, extending the Workflow RO-Crate profile (v1.0). This profile provides a standard schema for delineating workflow products. While there are variants of this workflow product schema for the Common Workflow Language (CWL) and Galaxy, a Globus Flows variant is not currently available.</p>
<p>To meet the specific needs of LivePublication, a two-fold approach is taken in the design of the orchestration artefact. The artefact outlines both the Workflow Execution Plan (WEP), which describes the Globus flow itself, and the Workflow Execution Description (WED), which details the actual instance of the workflows execution, containing generated LPAP artefacts. Find an example orchestration RO-Crate <a href="http://130.216.217.137:8080/">here</a>.</p>
<p>While RO-Crate offers promising features and capabilities for LPAP artefact representation and management, research to devise and refine RO-Crate profiles specifically tailored for LivePublication is ongoing. These profiles will aim to provide a unified schema for both the LPAP artefacts and the overarching orchestration node artefact, enabling the systematic assembly of complex flow outputs.</p>
</section>
</section>
<section id="l3-publication---presentation-and-integration" class="level2">
<h2 class="anchored" data-anchor-id="l3-publication---presentation-and-integration">L3: Publication - presentation and integration</h2>
<p>The Publication layer (level 3) is the most nascent layer and is predicated upon the generated orchestration RO-Crate artefact as described in <a href="#sec-artefact_generation">Section&nbsp;4.2.1.2</a>. This RO-Crate is directly integrated with a website, hosted on the orchestration node, providing a platform for generative- and author-driven content to be displayed.</p>
<p>Linking between the website content and resultant RO-Crate is achieved through static indexing of workflow outcomes and artefacts. This enables an ‘adaptor’ which ingests and updates the publication with each successive workflow execution. Figures, tables, and data are linked to the publication, allowing the author to reference and use these artefacts within the content of the paper.</p>
<p>Generative content created using LLMs and strict data inputs such as the Workflow Execution Plan, enable sections of a publication (e.g., methodology) to be automatically generated upon execution of the Globus flow. Research on constraining the possibility of hallucination, and including useful supplementary data from the Workflow Execution Description (e.g., time taken per step, descriptive metadata provided by the author) is ongoing.</p>
<p>The current version of the publication layer has some limitations. At present, the generated article largely relies on static indexing of workflow outcomes and artefacts, enforcing a rigid deployment mechanism through custom adaptors. Further, the integration of author driven content and live artefacts is limited by a lack of internal linking and logic rules regarding the publications content. These features are currently being addressed in ongoing research to develop a publication artefact schema designed specifically for publication deployment.</p>
</section>
</section>
<section id="sec-case_study" class="level1 page-columns page-full">
<h1>Comparative Language Identification Case Study</h1>
<p>This section demonstrates a practical application of the technology elaborated upon in <a href="#sec-Implementing_LP">Section&nbsp;4</a>. Hundreds of research articles are published every year using language models that are trained on massive and changing online datasets, making them excellent candidates for live publication. Here we present a comparative case study of two popular language identification models: <a href="https://pypi.org/project/fasttext/0.9.2/">fastText v0.9.2</a> and <a href="https://pypi.org/project/langdetect/">langdetect v1.0.9</a></p>
<p>We use a standard language identification dataset, which can be accessed <a href="https://huggingface.co/datasets/papluca/language-identification/viewer/papluca--language-identification/validation">here</a>. Both models ingest the dataset and generate ISO 639-3 language codes <a href="http://130.216.217.137:8080/">accessed here</a> as outputs. These codes are then processed by the statistics LPAP for analysis and content generation. The entire process is orchestrated as a Globus flow, as depicted in <a href="#fig-LID_flow">Figure&nbsp;5</a>.</p>
<div class="column-body-outset">
<div id="fig-LID_flow" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Figures/LiD_flow.png" class="img-fluid figure-img" alt="LID case study Globus Flow representation"></p>
<figcaption class="figure-caption">Figure&nbsp;5: LivePublication language identification comparison flow</figcaption>
</figure>
</div>
</div>
<p>The completion of the Globus flow results in the creation of LP artefacts generated by each LPAP. These artefacts serve as containers of information, capturing the details and outcomes of each computational step within the flow. They are subsequently integrated into a unified, orchestration RO-Crate <a href="#fig-human_readable_RO_Crate">Figure&nbsp;7</a>. This RO-Crate serves as the data model which drives the LivePublication. The complete RO-Crate, which provides a detailed view of the data and processes can be <a href="http://130.216.217.137:8080/">accessed here</a>.</p>
<div class="column-page">
<div class="column" style="width:45%;">
<div id="fig-LID_LP" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="http://130.216.217.47:8080/papers/lid-method-comparison-lp"><img src="Figures/LiD_LP.png" class="img-fluid figure-img" alt="Publication integrated with LivePublication outputs"></a></p>
<figcaption class="figure-caption">Figure&nbsp;6: Natural language article</figcaption>
</figure>
</div>
</div>
<div class="column" style="width:3%;">

</div>
<div class="column" style="width:45%;">
<div id="fig-human_readable_RO_Crate" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><a href="http://130.216.217.137:8080/"><img src="Figures/rocrate-human.png" class="img-fluid figure-img" alt="Human readable version of Orchestration RO-Crate"></a></p>
<figcaption class="figure-caption">Figure&nbsp;7: Orchestration RO-Crate outputs</figcaption>
</figure>
</div>
</div>
</div>
<p>Using the generated data and figures from the statistics LPAP, we <a href="https://livepublication.github.io/LP_Pub_LID/">link a publication</a> to these live, updating outputs (<a href="#fig-LID_LP">Figure&nbsp;6</a>). Metrics generated via the statistics node, such as accuracy per language, are included as live artefacts within the publication itself. Furthermore, we show that simple GPT-4 integration, primed with the input: <code>Generate a description of this workflow, from the perspective of an academic methodological section: &lt;WEP&gt;</code> generates correct, reflective descriptions of the computational methodology.</p>
<p>As the underling RO-Crate data model matures, and further systems are developed to take advantage of live data, more complex LivePublication systems will be possible, enabling a wider range of behaviours.</p>
</section>
<section id="sec-futurework" class="level1">
<h1>Conclusions and Future Work</h1>
<p>As the tools that we use to enable our scientific methodologies become increasingly computationally bound, eScience communities and developers have explored how we can enable scalable and accessible science though the use of workflow platforms, virtual laboratories, and scientific gateways. Conversely, scientific communication within computationally-enabled domains has seen less-focused development, leading to increasingly inefficient reporting of outcomes and low reproducibility and reuse within our publications.</p>
<p>Recent efforts towards facilitating better scholarly communication—such as developing ways to share research objects, providing virtual laboratory platforms for collaborative work, and designing self-contained, executable articles—have made significant strides towards an integrated future, where computational methods and results are fundamental parts of their respective publications. However, there still remains a gap between how data is collected, our scientific workflow practices, and how we communicate our results. In order to address this gap we identified six key attributes that any system designed to capture a comprehensive and dynamic account of computational research must satisfy: <strong>liveness</strong>, <strong>reproducibility</strong>, <strong>reusability</strong>, <strong>transparency</strong>, <strong>distribution</strong>, and <strong>completeness</strong>.</p>
<p>LivePublication brings these attributes together in one framework by building upon prior work (Globus and RO-Crate) to create a system that integrates article publication with live data sources and the execution of distributed scientific workflows. The result is a platform where a publication is designed once and executed many times in a form of live science—i.e., the content reflects the outcomes of the most recent method execution. Additionally, using the underlying workflow integration in a language model case study, we demonstrated that we can embed rich information on workflow execution—input data, results, timings—directly into the content of the live publication.</p>
<p>As we look to the future, we are focusing our efforts on developing tooling that will further integrate Layer 2 Artefacts with Level 3 Publications. The result will be a self-contained, self-descriptive publication artefact that includes all descriptive content needed to present the research to readers, ready for deployment online.</p>
<p>The development of this publication artefact will involve experimental content generation, including:</p>
<ul>
<li><strong>Self-documenting descriptions</strong>: Workflow and methodology descriptions that automatically generate documentation, giving insight into computational processes they encapsulate;</li>
<li><strong>Generative stitching of author-provided content</strong>: Automated integration of author-provided narrative with computational results;</li>
<li><strong>Dynamic content inclusion/exclusion criteria</strong>: Flexible rules to determine what content is included or excluded from the final publication based on computational outputs;</li>
<li><strong>Hybrid dynamic content</strong>: Content that adapts based on the underlying RO-Crate model, blending author-written narrative with live results.</li>
</ul>
<p>In addition, ongoing research is exploring how live science can further enrich the publication process itself. As a framework for developing live, reflective publications, LivePublication can monitor the change in results and methodologies over the lifecycle of an experiment. Enabling versioning and comparative views can provide a method of insight into the performance of new methods and results.</p>
</section>
<section id="references" class="level1">

<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" role="list">
<div id="ref-aufreiter2018stencila" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">Aufreiter, M. et al. 2018. Stencila–an office suite for reproducible research. <em>eLife Labs [Internet]</em>. 2, (2018).</div>
</div>
<div id="ref-baker20161" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">Baker, M. 2016. 1,500 scientists lift the lid on reproducibility. <em>Nature</em>. 533, 7604 (2016).</div>
</div>
<div id="ref-baker2016reproducibility" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">Baker, M. 2016. Reproducibility crisis. <em>Nature</em>. 533, 26 (2016), 353–66.</div>
</div>
<div id="ref-bechhofer2013linked" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Bechhofer, S. et al. 2013. Why linked data is not enough for scientists. <em>FGCS</em>. 29, 2 (2013), 599–611.</div>
</div>
<div id="ref-bisong2019google" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Bisong, E. and Bisong, E. 2019. Google colaboratory. <em>Building machine learning and deep learning models on google cloud platform: a comprehensive guide for beginners</em>. (2019), 59–64.</div>
</div>
<div id="ref-brammer2011paper" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Brammer, G.R. et al. 2011. Paper m<span>â</span>ch<span>é</span>: Creating dynamic reproducible science. <em>Procedia Computer Science</em>. 4, (2011), 658–667.</div>
</div>
<div id="ref-brinckman2019computing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Brinckman, A. et al. 2019. Computing environments for reproducibility: Capturing the <span>“whole tale.”</span> <em>FGCS</em>. 94, (2019), 854–867.</div>
</div>
<div id="ref-cervera2019anduril" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Cervera, A. et al. 2019. Anduril 2: Upgraded large-scale data integration framework. <em>Bioinformatics</em>. 35, 19 (2019), 3815–3817.</div>
</div>
<div id="ref-crusoe2022methods" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Crusoe, M.R. et al. 2022. Methods included: Standardizing computational reuse and portability with the common workflow language. <em>Commun. ACM</em>. 65, 6 (2022), 54–63.</div>
</div>
<div id="ref-deelman2015pegasus" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">Deelman, E. et al. 2015. Pegasus, a workflow management system for science automation. <em>FGCS</em>. 46, (2015), 17–35.</div>
</div>
<div id="ref-ellerm2022enabling" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">Ellerm, A. et al. 2022. Enabling LivePublication. <em>2022 IEEE 18th international conference on e-science</em> (2022), 419–420.</div>
</div>
<div id="ref-foster1998globus" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">Foster, I. and Kesselman, C. 1998. The <span>G</span>lobus project: A status report. <em>Proceedings seventh heterogeneous computing workshop (HCW’98)</em> (1998), 4–18.</div>
</div>
<div id="ref-ghosh2017very" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">Ghosh, S.S. et al. 2017. A very simple, re-executable neuroimaging publication. <em>F1000 Research</em>. 6, (2017).</div>
</div>
<div id="ref-goble2010myexperiment" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">Goble, C.A. et al. 2010. myExperiment: A repository and social network for the sharing of bioinformatics workflows. <em>Nucleic acids research</em>. 38, suppl_2 (2010), W677–W682.</div>
</div>
<div id="ref-huber2020aiida" class="csl-entry" role="listitem">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">Huber, S.P. et al. 2020. <span>AiiDA</span> 1.0, a scalable computational infrastructure for automated reproducible workflows and data provenance. <em>Scientific data</em>. 7, 1 (2020), 300.</div>
</div>
<div id="ref-jalili2020galaxy" class="csl-entry" role="listitem">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">Jalili, V. et al. 2020. The <span>G</span>alaxy platform for accessible, reproducible and collaborative biomedical analyses: 2020 update. <em>Nucleic acids research</em>. 48, W1 (2020), W395–W402.</div>
</div>
<div id="ref-kluyver2016jupyter" class="csl-entry" role="listitem">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">Kluyver, T. et al. 2016. Jupyter notebooks–a publishing format for reproducible computational workflows. <em>Positioning and power in academic publishing: Players, agents and agendas</em>. IOS Press. 87–90.</div>
</div>
<div id="ref-lasser2020creating" class="csl-entry" role="listitem">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">Lasser, J. 2020. Creating an executable paper is a journey through <span>Open Science</span>. <em>Commun. Physics</em>. 3, 1 (2020), 143.</div>
</div>
<div id="ref-mclennan2010hubzero" class="csl-entry" role="listitem">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">McLennan, M. and Kennell, R. 2010. <span>HUBzero</span>: A platform for dissemination and collaboration in computational science and engineering. <em>CiSE</em>. 12, 2 (2010), 48–53.</div>
</div>
<div id="ref-miller2011cipres" class="csl-entry" role="listitem">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">Miller, M.A. et al. 2011. The CIPRES science gateway: A community resource for phylogenetic analyses. <em>Proc. 2011 TeraGrid conference: Extreme digital discovery</em> (2011), 1–8.</div>
</div>
<div id="ref-nickerson2017introducing" class="csl-entry" role="listitem">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">Nickerson, D.P. and Hunter, P.J. 2017. Introducing the <span>P</span>hysiome journal: Improving reproducibility, reuse, and discovery of computational models. <em>2017 IEEE 13th international conference on e-science</em> (2017), 448–449.</div>
</div>
<div id="ref-soiland2022packaging" class="csl-entry" role="listitem">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">Soiland-Reyes, S. et al. 2022. Packaging research artefacts with RO-crate. <em>Data Science</em>. 5, 2 (2022), 97–138.</div>
</div>
<div id="ref-stodden2015researchcompendia" class="csl-entry" role="listitem">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">Stodden, V. et al. 2015. Researchcompendia.org: Cyberinfrastructure for reproducibility and collaboration in computational science. <em>CiSE</em>. 17, 1 (2015), 12–19.</div>
</div>
<div id="ref-strijkers2011toward" class="csl-entry" role="listitem">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">Strijkers, R.J. et al. 2011. Toward executable scientific publications. <em>ICCS</em> (2011), 707–715.</div>
</div>
<div id="ref-Way_Community_The_Turing2019-qd" class="csl-entry" role="listitem">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">The Turing Way Community et al. 2019. The turing way: A handbook for reproducible data science. <a href="https://ui.adsabs.harvard.edu/abs/2019zndo...3233986W" class="uri">https://ui.adsabs.harvard.edu/abs/2019zndo...3233986W</a>.</div>
</div>
<div id="ref-vescovi2022linking" class="csl-entry" role="listitem">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">Vescovi, R. et al. 2022. Linking scientific instruments and computation: Patterns, technologies, and experiences. <em>Patterns</em>. 3, 10 (2022), 100606.</div>
</div>
<div id="ref-wilkinson2016fair" class="csl-entry" role="listitem">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">Wilkinson, M.D. et al. 2016. The <span>FAIR</span> guiding principles for scientific data management and stewardship. <em>Scientific data</em>. 3, 1 (2016), 1–9.</div>
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction {#sec-introduction}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>The way that science is published has not changed substantially in 350 years, despite the obvious limitations of a static and incomplete account of the research performed.  This is especially true for research that is 'born digital' where rich representations are removed in order to fit into the traditional article container literally a paper, or more recently a pdf. As the computational support of science becomes richer, the process of communicating a full and reproducible account of what was done has grown increasingly possible, but also increasingly cumbersome @baker20161.</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>To address this the FAIR principles call for co-publication of code and data alongside the original research article @wilkinson2016fair. When an article is published alongside the accompanying code and data, it significantly enhances the potential for reuse, reproducibility, and transparency of the work. However, there remain many other unrealised improvements that we seek here to create fully reproducible, explainable, and self-updating (`live') publications, ensuring other researchers can effectively understand, validate, and build upon the work. </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>Our overall aim is to create a single container for a fully complete account of some conducted research, including data (even if remotely accessed), workflows, code, mathematics, tables and figures, and text.  And then to allow artefacts to be modified in response to newer or better versions becoming available.  The simplest example of this is a research article describing some dynamic phenomenon (such as the state of a pandemic or an ocean circulation model) that automatically updates itself when new data is available. </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>While supplementing traditional research articles with additional research artefacts has gained popularity, emerging research platforms are offering innovative ways to capture and communicate a scientist's workflow more fully. Platforms like Galaxy @jalili2020galaxy and Physiome @nickerson2017introducing facilitate the publication of computational workflows, models, and tools, while also offering remote execution services that promote the development of virtual laboratories and foster collaboration. Meanwhile, software tools such as Jupyter Notebooks @kluyver2016jupyter and Stencila @aufreiter2018stencila combine code, data, and descriptive elements, enabling interactive sessions that provide users with hands-on experience and a deeper understanding of the methodology. </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>These two perspectives---augmentation of traditional articles and development of new publication methods---both seek to resolve the gap between research performed and research communicated. Publication platforms that integrate executable code, data, and descriptive elements address foundational issues such as reproducibility, reuse, and transparency. Furthermore, they unlock the potential for innovative changes, such as creating dynamic research articles that respond to changes in their originating workflows, even once they have been published.</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>This paper introduces a novel framework called *LivePublication* that seamlessly integrates highly distributed computational workflows, data, and descriptive elements. Its primary goal is to deliver dynamic, live research articles that accurately reflect the current state of the computational pipeline, thereby providing a more interactive and up-to-date representation of the research process. In fields where constant surveillance or regular data and algorithm improvements are common---e.g., environmental science and  pandemic monitoring---much published research is out of date even before it appears in print. This leads to huge inefficiencies and reliability issues, and new publications that only serve to update the data or methods. Integrating research articles with *distributed* computational workflows is an essential intricacy, as complex computational workflows often demand scalability, portability, and compartmentalisation of components. Distributed computational environments also offer potential for novel extensibility use cases and can foster enhanced communication and understanding of the underlying scientific methodology.</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>After reviewing related work on co-publication, executable articles, workflow platforms, and virtual laboratories in next section, the required attributes of the LivePublication framework are introduced in @sec-LP_framework. Following that, in @sec-Implementing_LP we describe an instantiation of LivePublication that satisfies these requirements, leveraging prior work on Globus and the RO-Crate method. In @sec-case_study we demonstrate the utility of this approach with a natural language processing case study. Finally, we end with our vision for LivePublication going forward and plans for future work.</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu"># Background {#sec-background}</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>The reproducibility crisis @baker2016reproducibility has led to a call for more transparent, repeatable, and verifiable research. The FAIR principles (Findable, Accessible, Interoperable, and Reusable), developed by Wilkinson et al. @wilkinson2016fair, provide guidelines for enhancing the reproducibility and transparency of research data and methods. Co-publication, where code, data, and external resources are published alongside traditional articles is one solution. This approach has been adopted widely, e.g., <span class="co">[</span><span class="ot">Papers with Code</span><span class="co">](https://portal.paperswithcode.com/)</span>, <span class="co">[</span><span class="ot">Zenodo</span><span class="co">](https://zenodo.org)</span>, and Research Compendium @stodden2015researchcompendia.  This mode of publication enables reproduction and reuse, reducing inefficiencies in research processes.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>In contrast to co-publication, 'executable articles' combine data, methods, and natural language content to create interactive documents that can be re-executed to reproduce original results or generate new insights @lasser2020creating. Tools such as Jupyter Notebooks @kluyver2016jupyter, Google Colaboratory @bisong2019google, and Stencila @aufreiter2018stencila interweave text with code cells to facilitate step-by-step, reproducible computations. In a slightly different approach, solutions like Paper Mâché @brammer2011paper, Executable Paper @strijkers2011toward, and Ghosh et al.'s neuroimaging re-executable publication @ghosh2017very separate the code and data from narrative text, providing a traditional article with re-execution capabilities. Our own previous effort @ellerm2022enabling integrates workflows and natural language text by combining Common Workflow Language (CWL) descriptions, execution capabilities, and author-written content on a central server. </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>The bioinformatics and biomedical communities in particular have developed many domain-specific workflow platforms. For example, Galaxy and Anduil 2 <span class="co">[</span><span class="ot">@jalili2020galaxy; @cervera2019anduril</span><span class="co">]</span> provide workflow capabilities and thus code abstraction and reuse of computational components. General workflow frameworks like Pegasus, CWL, and AiiDA <span class="co">[</span><span class="ot">@deelman2015pegasus; @crusoe2022methods; @huber2020aiida</span><span class="co">]</span> are geared towards providing universal solutions, with mechanisms to customise and develop bespoke workflows to meet diverse research needs. In industry, Amazon and Google both provide workflow platforms for cloud infrastructure. Workflow technologies provide some abstraction for complex, reusable scientific methodologies. It is this abstraction that serves as an interface for building and exporting artefacts, ready for integration into a publication medium (as described in @sec-LP_architecture).</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>Virtual laboratories and scientific gateways abstract the complexity of underlying computational infrastructure, offering scientists an accessible and intuitive interface for conducting research. <span class="co">[</span><span class="ot">Code Ocean</span><span class="co">](https://codeocean.com)</span>, HubZero @mclennan2010hubzero, and CIPRES @miller2011cipres offer tools for domain specific data management, analysis, and visualisation. MyExperiment and Wholetale <span class="co">[</span><span class="ot">@goble2010myexperiment; @brinckman2019computing</span><span class="co">]</span> are examples of virtual laboratories, serving as collaborative environments where researchers can create, share, and execute scientific workflows.</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>LivePublication extends the capabilities of these platforms by directly interfacing with live workflow platforms and generating article-like outputs. This moves us towards a more dynamic, interactive, and up-to-date representation of research. </span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="fu"># LivePublication Framework {#sec-LP_framework}</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>The design of LivePublication reflects the need to satisfy a dual set of functional requirements: those of computational workflows and of the publication process. Prior solutions to overcome gaps in publication often overlook the role of complex computational pipelines in science. Therefore, the LivePublication framework is designed to exhibit six key attributes: </span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Liveness**: live links to all the computational resources used in a workflow, so that it can be responsive to changes (such as new data);</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Reproducibility**: replication of the same results / conclusions given the computational method and data;</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="ss"> 3. </span>**Reusability/Extensibility**: reuse of, or extension of, the computational pipeline components;</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Transparency**: the ability to inspect the computational pipeline, with tools to automatically derive text descriptions of workflow and code;</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Distribution**: support for complex, distributed computational pipelines and data repositories;</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Completeness**: The methods, data, workflow, results, and findings are held within a single container, with their inter-dependencies intact.</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>The concept of 'reproducibility' is best defined by The Turing Way @Way_Community_The_Turing2019-qd, which delineates reproducibility into four distinct categories based on analysis and data: Reproducible, Replicable, Robust, and Generalizable. We adopt these definitions for clarity and precision in discussing LivePublication. A fundamental requirement of a LivePublication instance is reproducibility, as each LivePublication is generated through the periodic re-execution of its underlying computational pipeline. Depending on the extensibility and reusability of a given instance, as supported by its underlying infrastructure, it can also meet the conditions for being replicable and robust.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>Reusability, within the LivePublication framework, refers to the ability of methods---both computational and broader scientific methodologies---to be reused by a third party. At its simplest, the inclusion of static code within the publication can satisfy the basic reusability criteria established by many journals. The LivePublication computational pipeline can enable more dynamic forms of reuse. For instance, where portions of the computational workflow can be repurposed and incorporated by external parties, emulating the code execution behaviour seen in tools like Jupyter notebooks @kluyver2016jupyter. </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Transparency in LivePublication extends beyond simple code availability. It encapsulates the clarity of the methodology: its communication and the precision of that communication. A transparent method provides tools that enable users to understand the process in question and make informed value judgements about its application. LivePublication facilitates more comprehensive descriptions via computational methods to automatically generate various levels of text description of both code and workflow. </span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>Distribution is addressed via scalability and data locality. Beyond these pragmatic concerns, distributed pipelines offer significant value in terms of their inherent modular structure. By compartmentalising methods into granular computational units, we enhance both reusability and extensibility. Finally, completeness is achieved by bringing all aspects of a science experiment, from the data to the resulting publication, into a single container.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## LivePublication architecture {#sec-LP_architecture}</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>An overview of the LivePublication technology stack is provided in @fig-highlevel_architecture and shows the three conceptual levels of the architecture. </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="al">![High-level LivePublication architecture](Figures/Highlevel-architecture.png)</span>{fig-alt="LivePublication architecture outline" #fig-highlevel_architecture width=75%}</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>The foundation *Layer 1*, denoted as *Hardware / Infrastructure / Aggregate Systems*, encompasses the essential technology necessary for the distributed computational workflow. This can include a myriad of components, from virtual machines and scientific instruments (like sensors and speciality hardware) to data stores and other enabling technologies. Despite the potential diversity in form, each component must meet certain prerequisites to participate within a distributed workflow---namely, they must be accessible and actionable by a workflow management system.</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>Moving up to *Level 2*, two concurrent components are presented representing a primary innovation of the LivePublication framework. Sitting upon the hardware layer, the Workflow and Data Management systems orchestrate the computational process. Development efforts are actively underway for tools that manage workflow execution. Galaxy @jalili2020galaxy, Globus @foster1998globus, Pegasus @deelman2015pegasus, and CWL @crusoe2022methods represent a handful of well-known workflow management tools, each with its unique focus and priorities. For the LivePublication context, tools that emphasise robust data management techniques, such as data locality, efficient data transfer at scale, and cross-boundary data transfer, are particularly advantageous. These tools align well with the functional requirements of today's researchers and can effectively facilitate the creation of a LivePublication.</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>LivePublication Artefact Generation occurs concurrently, and agnostically, of workflow execution. Essentially, each step or computational unit generates a descriptive artefact, documenting its execution and the ensuing results. This critical process forms the cornerstone of integrating workflow executions with publication media, offering a mechanism for distilling information from multiple computational steps and preserving their outputs for subsequent processing. By maintaining a clear and detailed record of each step of the scientific process (not just those steps conducted locally), it not only enhances transparency but also greatly facilitates reproducibility and extensibility.</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>Finally, *Level 3 -- Publication: Presentation and Integration* serves as the integration point for LivePublication artefacts, synthesising the outputs of the executed workflow into a cohesive, comprehensive account. This includes the results of the computational process like figures and resultant data, as well as the publication artefacts generated during the workflow execution. Beyond these, it can incorporate additional information such as workflow definition, versioning details, and other supplementary information, providing a rich, detailed snapshot of the entire scientific process. </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="fu"># Implementing LivePublication {#sec-Implementing_LP}</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>This section discusses the specific technologies that have been chosen to actualise LivePublication, showing how integration between distributed workflows and publications can be achieved. In particular, we highlight how these technologies facilitate seamless information integration between distributed workflows and the subsequent publication process.</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="fu">## L1: Cloud computing</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>Cloud computing services are a natural choice for implementing *Layer 1* due to their scalability and flexibility, accommodating the variable computational and data storage needs inherent in scientific workflows. Our initial implementation of LivePublication uses the <span class="co">[</span><span class="ot">Nectar Research Cloud</span><span class="co">](www.nectar.org.au)</span>, an OpenStack-based cloud computing platform, due to its availability, flexibility, and control that OpenStack provides over the deployed infrastructure. These qualities directly align with the LivePublication design objectives, particularly in terms of extensibility and distributed computing, as they allow for customisation and seamless integration with various computational workflows. OpenStack's open-source nature further facilitates this by encouraging collaboration and customisation, making it a fitting choice for LivePublication.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="fu">## L2: Workflow orchestration and artefact generation {#sec-workflow_platforms}</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="fu">### Workflow orchestration</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>Transitioning to *Layer 2*, we turn our focus to workflow management. The choice of workflow platform is a significant decision, as LivePublication relies on the close integration of workflow execution and artefact generation. LivePublication requires access to each computational step in a workflow's execution, providing an interface to generate and export a descriptive artefact (*LP Artefact*) for later processing. So the workflow platform must be open source, and support custom behaviours and plugins. While several workflow platforms do offer means to implement custom workflow steps <span class="co">[</span><span class="ot">@crusoe2022methods; @huber2020aiida; @jalili2020galaxy</span><span class="co">]</span>, we here take the view that outcomes of a step (LP Artefacts) are better represented as external to the step itself, as generalised pre/post processing for a custom LivePublication class of workflow.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>A custom Globus AP template has been developed to support the integration of LivePublication with Globus flows. The template is a simple Flask REST server, providing the base functionality to integrate with the Globus-Auth service and enabling LivePublication artefact generation (covered in the next section). Each LivePublication Action Provider (LPAP) is extended in three important ways:</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Containerisation**: Packaging the computational method as a Docker container;</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Artefact Generation**: Functionality to generate LP artefacts and integrate metadata;</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Artefact Transfer**: Automating reliable transfer of generated LP artefacts for subsequent processing.</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>Each LPAP contains a Docker image of the computational method it executes as its service. Packaging the method in this way provides four primary advantages: environment management, reuse and inclusion, parallelisation, and AP maintenance. </span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Containerisation</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>Abstracting the execution environment from the server environment is required as many computational methods rely on specific dependencies and configurations for their execution. Docker images are integrated with LPAPs through a mirrored directory structure shared between the image and server. LPAPs include *input* and *output* directories which map to directories of the same name within the docker container. This allows incoming data to be ingested, and processed data to be exported, between the container and servers contexts. Further, these standard directories enable the inclusion of both incoming data and processed data within LP Artefacts. </span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>Containerisation enables us to bundle the computational method within an LP artefact. Moreover, containers are capable of handling numerous incoming action requests simultaneously, scaling well. Lastly, containerisation fosters an agile development environment and simplifies the maintenance of the AP's method. By encapsulating each service within its container, modifications can be made without disrupting the entire system, contributing to a more resilient and manageable system overall. </span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Artefact generation {#sec-artefact_generation}</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>For the generation of LP artefacts, we have developed an open-source Python library <span class="in">`lp_ap_tools`</span>. A Python decorator (@lst-lp_ap_tools) encapsulates the execution of the computational method's Docker container within the LPAP. By wrapping the executed method in this decorator, metadata mining and information gathering can be performed both pre- and post-execution. </span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="in">```{#lst-lp_ap_tools .python lst-cap="LP_artefact decorator"}</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="in">@LP_artefact(dir_struct=directory_structure)</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="in">def run_computation(**arguments):</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="in">  # Execute method container</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="in">  container = client.containers.run(</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="in">  image='computation_image:latest',</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="in">    volumes=volumes,</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a><span class="in">    detach=True</span></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a><span class="in">  )</span></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>Pre-execution information and metadata draws on three primary sources: the LPAP, Globus services, and the server's operating system. Each LPAP is equipped with descriptive fields, for example name, description, and keywords, which are integrated into the LivePublication artefacts. Additionally, the <span class="in">`lp_ap_tools`</span> library provides a means for customising and incorporating LivePublication-specific fields into the AP's parameters dynamically, enriching the scope of data included in LivePublication artefacts. For example, a <span class="in">`user_comment`</span> field can be integrated into both REST parameters and LivePublication artefacts automatically. Further, the inclusion of source code and execution environment information is made possible by the incorporation of docker build files and respective code. Globus services, such as Globus-Auth, can be utilised to gather relevant details about the user, e.g. name and affiliation, and finally a full description of the hardware and configuration details of the AP can be retrieved from the server.</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>During the execution of the method, measurements can be taken, for example, execution time and resource utilisation. Currently, there is no system in place for interfacing and exporting measurements from inside the method's container, however this possibility provides a further avenue for exporting descriptive metadata. Post-execution information and metadata primarily consists of the computational results: data, figures, and/or text which is included within the artefact. </span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Artefact transfer</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>Upon completing a flow consisting of LPAPs, each AP is responsible for transferring their corresponding artefacts to a designated orachestration node for collation and further processing. This is achieved by including a <span class="in">`orchestration_node_id`</span> parameter in each LPAP, which is expected to contain a Globus endpoint ID. The LPAPs are configured to request permissions for the Globus transfer API, thereby granting them the authority to execute transfers on behalf of the user. Upon completion of an AP's tasks, the LPAPs utilise the Globus transfer API to transmit their results to the assigned orchestration node.</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Orchestration node</span></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>Given a set of LPAPs, the orchestration node manages them to form a flow. The orchestration node provides two functions:</span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dispatches Globus flows**: Initiates the execution of workflows, composed from a series of LPAPs and Globus APs;</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Collects and processes LPAP artefacts**: Gathers and processes the artefacts from each LPAP</span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a>The orchestration node achieves these functions using Gladier @vescovi2022linking, a Globus SDK, which enables the node to programmatically construct workflows from individual descriptions of LPAPs and Globus transfer APs. This capability allows the node to flexibly orchestrate workflows (and LivePublications), which can be adjusted as needed to suit varying use cases. </span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>As an example, consider a flow that includes LPAPs *Process_one* and *Process_two*. The orchestration node generates a simple flow description as follows:</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{#lst-WEP .json lst-cap="Generated Workflow Execution Plan"}</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a><span class="in">{</span></span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a><span class="in">  "Comment": "&lt;Comment&gt;",</span></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="in">  "StartAt": "Process_one",</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a><span class="in">  "States": {</span></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a><span class="in">    "Process_one": {</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a><span class="in">      "ActionScope": "&lt;ActionScope&gt;",</span></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="in">      "ActionUrl": "&lt;ActionUrl&gt;",</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="in">      "Parameters": {</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="in">        "orchestration_node_id": "&lt;orch_id&gt;"</span></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="in">      },</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="in">      "ResultPath": "&lt;ResultPath&gt;",</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="in">      "next": "Process_two"</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a><span class="in">    },</span></span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a><span class="in">    "Process_two": {</span></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a><span class="in">      "ActionScope": "&lt;ActionScope&gt;",</span></span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a><span class="in">      "ActionUrl": "&lt;ActionUrl&gt;",</span></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="in">      "Parameters": {</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a><span class="in">        "orchestration_node_id": "&lt;orch_id&gt;"</span></span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a><span class="in">      },</span></span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a><span class="in">      "ResultPath": "&lt;ResultPath&gt;",</span></span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a><span class="in">      "End": True</span></span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a><span class="in">    }</span></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>This flow description is then submitted to Globus using the users credentials. Gladier oversees the workflow's execution, and the orchestration node simultaneously collects generated LPAP artefacts. Upon the completion of a workflow, the orchestration node gathers a description of the flow's execution returned by Globus, and embeds this information into a unique artefact specific to the orchestration node. This artefact provides a comprehensive depiction of the Globus flow's execution, including details about each step, its identifying parameters, and additional metadata. </span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>The information held within this artefact includes but is not limited to: the action ID, the completion time, the status, and flow ID. Essentially, this artefact provides a blueprint of the execution path of the Globus flow. Here is an example of such an execution description: </span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{#lst-WED .json lst-cap="Completed Workflow Execution Description"}</span></span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a><span class="in">{</span></span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a><span class="in">  "action_id": "&lt;action_id&gt;",</span></span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a><span class="in">  "completion_time": "&lt;completion_time&gt;",</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a><span class="in">  "display_status": "&lt;display_status&gt;",</span></span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a><span class="in">  "flow_id": "&lt;flow_id&gt;",</span></span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a><span class="in">  "details": {</span></span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a><span class="in">    "output": {</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a><span class="in">      "Process_one": {</span></span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a><span class="in">        "action_id": "&lt;action_id&gt;",</span></span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a><span class="in">        "completion_time": "&lt;completion_time&gt;",</span></span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a><span class="in">        "display_status": "&lt;display_status&gt;",</span></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="in">        "details": {}</span></span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a><span class="in">      },</span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a><span class="in">      "Process_two": {</span></span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a><span class="in">        "action_id": "&lt;action_id&gt;",</span></span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a><span class="in">        "completion_time": "&lt;completion_time&gt;",</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a><span class="in">        "display_status": "&lt;display_status&gt;",</span></span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a><span class="in">        "details": {}</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a><span class="in">      }</span></span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a><span class="in">    }</span></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a><span class="in">  }</span></span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a><span class="in">}</span></span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>The orchestration node artefact is a structure integrating separate LPAP artefacts. It does so by aligning the <span class="in">`action_id`</span> fields (@fig-comb_metadata), thereby forming a comprehensive account of the flow's execution. This process results in a holistic description, uniting the separate elements into an interconnected narrative of the workflow's path and outcomes. </span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a><span class="al">![Integrating LPAP artefacts](Figures/combining-metadata.png)</span>{fig-alt="Integrating LPAP data and Orchestration data" #fig-comb_metadata width=70%}</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>The result of this orchestration technique, utilising Globus APs, LPAPs, <span class="in">`lp_ap_tools`</span>, and Gladier orchestration node, is a generalised method for collecting, enriching, and exporting a full description of methods used during a computational workflow, including the methods themselves. A visual overview of this process is provided in @fig-Globus_LP_artefact_gen. At this stage, the integrated artefact performs well as a workflow provenance and reuse / reproducibility artefact. This technology, additionally, sets the groundwork for tight integration between the execution of a computational method, and the real-time generation live, representative publications. The LPAP template is <span class="co">[</span><span class="ot">available here</span><span class="co">](https://github.com/LivePublication/LP_GlobusAP_Template)</span>, demonstrating the practical implementation of custom AP services. </span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>::: {.column-body-outset}</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a><span class="al">![Integrating artefact generation and orchestration with Globus Flows (L2 of LivePublication Architecture)](Figures/Globus-LPArtefact.png)</span>{fig-alt="Depiction of artefact generation and orchestration using Globus Flows." #fig-Globus_LP_artefact_gen}</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a><span class="fu">### AP Artefacts</span></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>This section discusses the artefacts themselves, the technologies that enable their representation, and how they are poised to interface with *Layer 3* publications, as shown in @fig-highlevel_architecture. LP artefacts are dynamic objects that encapsulate data, results, and associated descriptive metadata from each computational step in a workflow. They are designed with two essential properties:</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Self-contained and describing**: Artefacts should encapsulate all the necessary information to describe the computation performed within a LPAP;</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Identifiable/Indexable**: Artefacts must have consistent, unique identifiers that allow them to be accurately referenced within a publication, specifically figures, tables, and other features</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>Each LPAP artefact contains a minimal set of data required to express the methods and results generated during its action. This must include a description of the purpose and intended application context of the LPAP, the methods used to achieve this purpose, and finally the generated results and data used. This requirement achieves two purposes. First, it ensures that each LPAP artefact is a discrete, stand-alone package of information regarding the execution of an AP, and second, it provides the minimal amount of information for methodology descriptions that can be woven into the publication. </span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>The final, collated artefact must maintain consistent identifiers for use as references within the publication layer. Generated files within a flow may be inconsistent dependent on input data and flow design. To ensure consistency, LPAPs need to associate unique identifiers with their expected outputs. However there is room for further research to develop a universally applicable solution for internal identifiers, ensuring consistent reference from the point of artefact generation to publication.</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a>To build artefacts that reflect these qualities, the RO-Crate specification @soiland2022packaging was selected due to its versatility, extensibility, and compatibility with diverse data types and computational workflows. Furthermore, the existence of RO-Crate SDKs simplifies its implementation, making it an approachable option for development. Notably, RO-Crates can be converted to human-readable websites, providing a user-friendly way to interface these data-rich artefacts with the publication layer. </span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>RO-Crate is built around the concept of Research Objects (ROs), which align well with generated LPAP artefacts. ROs provide semantically rich, linked data, "bundling together essential information relating to experiments and investigations" <span class="co">[</span><span class="ot">Why linked data is not enough for scientists @bechhofer2013linked</span><span class="co">]</span>{.aside}. Bechhofer et al. @bechhofer2013linked discuss how ROs enable *Revealable* (auditable) experimentation, *Lifecycle* provenance recording, and *Versioning*, which align with LivePublication's publication layer. </span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>RO-Crate adds a descriptive specification grounded in <span class="in">`schema.org`</span> and articulated in JSON-LD. This allows RO-Crate objects to define heterogeneous research outputs via metadata and linked data. Conceptually, RO-Crate divides possible content into two categories: *Data Entities*---e.g. a file or directory, and *Contextual Entities*---external information stored via metadata. RO-Crate can define links between these entities, enabling relationship modelling and creating a rich, interconnected description of research outcomes. </span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>LPAP RO-Crate artefacts map a user (who executes the action within the flow) to an Action Provider (the actual provider being run) and its respective components, as depicted in @fig-LPAP_relationship_schema below.</span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="al">![Integrating LPAP artefacts](Figures/ROcrate_LPAP.png)</span>{fig-alt="LPAP RO-Crate relationship representation" #fig-LPAP_relationship_schema width=60%}</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>These individual LPAP RO-Crate artefacts are incorporated into the orchestration artefact via the orchestration node, extending the Workflow RO-Crate profile (v1.0). This profile provides a standard schema for delineating workflow products. While there are variants of this workflow product schema for the Common Workflow Language (CWL) and Galaxy, a Globus Flows variant is not currently available. </span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>To meet the specific needs of LivePublication, a two-fold approach is taken in the design of the orchestration artefact. The artefact outlines both the Workflow Execution Plan (WEP), which describes the Globus flow itself, and the Workflow Execution Description (WED), which details the actual instance of the workflows execution, containing generated LPAP artefacts. Find an example orchestration RO-Crate <span class="co">[</span><span class="ot">here</span><span class="co">](http://130.216.217.137:8080/)</span>.</span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>While RO-Crate offers promising features and capabilities for LPAP artefact representation and management, research to devise and refine RO-Crate profiles specifically tailored for LivePublication is ongoing. These profiles will aim to provide a unified schema for both the LPAP artefacts and the overarching orchestration node artefact, enabling the systematic assembly of complex flow outputs. </span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="fu">## L3: Publication - presentation and integration</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>The Publication layer (level 3) is the most nascent layer and is predicated upon the generated orchestration RO-Crate artefact as described in @sec-artefact_generation. This RO-Crate is directly integrated with a website, hosted on the orchestration node, providing a platform for generative- and author-driven content to be displayed. </span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>Linking between the website content and resultant RO-Crate is achieved through static indexing of workflow outcomes and artefacts. This enables an 'adaptor' which ingests and updates the publication with each successive workflow execution. Figures, tables, and data are linked to the publication, allowing the author to reference and use these artefacts within the content of the paper. </span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>Generative content created using LLMs and strict data inputs such as the Workflow Execution Plan, enable sections of a publication (e.g., methodology) to be automatically generated upon execution of the Globus flow. Research on constraining the possibility of hallucination, and including useful supplementary data from the Workflow Execution Description (e.g., time taken per step, descriptive metadata provided by the author) is ongoing. </span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a>The current version of the publication layer has some limitations. At present, the generated article largely relies on static indexing of workflow outcomes and artefacts, enforcing a rigid deployment mechanism through custom adaptors. Further, the integration of author driven content and live artefacts is limited by a lack of internal linking and logic rules regarding the publications content. These features are currently being addressed in ongoing research to develop a publication artefact schema designed specifically for publication deployment. </span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="fu"># Comparative Language Identification Case Study {#sec-case_study}</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>This section demonstrates a practical application of the technology elaborated upon in @sec-Implementing_LP. Hundreds of research articles are published every year using language models that are trained on massive and changing online datasets, making them excellent candidates for live publication. Here we present a comparative case study of two popular language identification models: <span class="co">[</span><span class="ot">fastText v0.9.2</span><span class="co">](https://pypi.org/project/fasttext/0.9.2/)</span> and <span class="co">[</span><span class="ot">langdetect v1.0.9</span><span class="co">](https://pypi.org/project/langdetect/)</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a>We use a standard language identification dataset, which can be accessed <span class="co">[</span><span class="ot">here</span><span class="co">](https://huggingface.co/datasets/papluca/language-identification/viewer/papluca--language-identification/validation)</span>. Both models ingest the dataset and generate ISO 639-3 language codes <span class="co">[</span><span class="ot">accessed here</span><span class="co">](http://130.216.217.137:8080/)</span> as outputs. These codes are then processed by the statistics LPAP for analysis and content generation. The entire process is orchestrated as a Globus flow, as depicted in @fig-LID_flow.</span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>::: {.column-body-outset}</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a><span class="al">![LivePublication language identification comparison flow](Figures/LiD_flow.png)</span>{fig-alt="LID case study Globus Flow representation" #fig-LID_flow}</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>The completion of the Globus flow results in the creation of LP artefacts generated by each LPAP. These artefacts serve as containers of information, capturing the details and outcomes of each computational step within the flow. They are subsequently integrated into a unified, orchestration RO-Crate @fig-human_readable_RO_Crate. This RO-Crate serves as the data model which drives the LivePublication. The complete RO-Crate, which provides a detailed view of the data and processes can be <span class="co">[</span><span class="ot">accessed here</span><span class="co">](http://130.216.217.137:8080/)</span>.</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>::: {.column-page}</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>:::{.column width="45%"}</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="al">![Natural language article](Figures/LiD_LP.png)</span><span class="ot">{fig-alt="Publication integrated with LivePublication outputs" #fig-LID_LP}</span><span class="co">](http://130.216.217.47:8080/papers/lid-method-comparison-lp)</span></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>:::{.column width="3%"}</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>:::{.column width="45%"}</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="al">![Orchestration RO-Crate outputs](Figures/rocrate-human.png)</span><span class="ot">{fig-alt="Human readable version of Orchestration RO-Crate" #fig-human_readable_RO_Crate}</span><span class="co">](http://130.216.217.137:8080/)</span></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>Using the generated data and figures from the statistics LPAP, we <span class="co">[</span><span class="ot">link a publication</span><span class="co">](https://livepublication.github.io/LP_Pub_LID/)</span> to these live, updating outputs (@fig-LID_LP). Metrics generated via the statistics node, such as accuracy per language, are included as live artefacts within the publication itself. Furthermore, we show that simple GPT-4 integration, primed with the input: <span class="in">`Generate a description of this workflow, from the perspective of an academic methodological section: &lt;WEP&gt;`</span> generates correct, reflective descriptions of the computational methodology.</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>As the underling RO-Crate data model matures, and further systems are developed to take advantage of live data, more complex LivePublication systems will be possible, enabling a wider range of behaviours.  </span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusions and Future Work {#sec-futurework}</span></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>As the tools that we use to enable our scientific methodologies become increasingly computationally bound, eScience communities and developers have explored how we can enable scalable and accessible science though the use of workflow platforms, virtual laboratories, and scientific gateways. Conversely, scientific communication within computationally-enabled domains has seen less-focused development, leading to increasingly inefficient reporting of outcomes and low reproducibility and reuse within our publications. </span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>Recent efforts towards facilitating better scholarly communication---such as developing ways to share research objects, providing virtual laboratory platforms for collaborative work, and designing self-contained, executable articles---have made significant strides towards an integrated future, where computational methods and results are fundamental parts of their respective publications. However, there still remains a gap between how data is collected, our scientific workflow practices, and how we communicate our results. In order to address this gap we identified six key attributes that any system designed to capture a comprehensive and dynamic account of computational research must satisfy: **liveness**, **reproducibility**, **reusability**, **transparency**, **distribution**, and **completeness**. </span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>LivePublication brings these attributes together in one framework by building upon prior work (Globus and RO-Crate) to create a system that integrates article publication with live data sources and the execution of distributed scientific workflows. The result is a platform where a publication is designed once and executed many times in a form of live science---i.e., the content reflects the outcomes of the most recent method execution. Additionally, using the underlying workflow integration in a language model case study, we demonstrated that we can embed rich information on workflow execution---input data, results, timings---directly into the content of the live publication.</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>As we look to the future, we are focusing our efforts on developing tooling that will further integrate Layer 2 Artefacts with Level 3 Publications. The result will be a self-contained, self-descriptive publication artefact that includes all descriptive content needed to present the research to readers, ready for deployment online.</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>The development of this publication artefact will involve experimental content generation, including: </span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Self-documenting descriptions**: Workflow and methodology descriptions that automatically generate documentation, giving insight into computational processes they encapsulate;</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Generative stitching of author-provided content**: Automated integration of author-provided narrative with computational results;</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dynamic content inclusion/exclusion criteria**: Flexible rules to determine what content is included or excluded from the final publication based on computational outputs;</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Hybrid dynamic content**: Content that adapts based on the underlying RO-Crate model, blending author-written narrative with live results. </span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a>In addition, ongoing research is exploring how live science can further enrich the publication process itself. As a framework for developing live, reflective publications, LivePublication can monitor the change in results and methodologies over the lifecycle of an experiment. Enabling versioning and comparative views can provide a method of insight into the performance of new methods and results. </span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-274"><a href="#cb1-274" aria-hidden="true" tabindex="-1"></a><span class="fu"># References</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<div class="page-columns page-rows-contents page-layout-article"><div class="social-share"><a href="https://twitter.com/share?url=https://mr.schochastics.net/&amp;text=awesome page" target="_blank" class="twitter"><i class="fab fa-twitter fa-fw fa-lg"></i></a><a href="https://www.linkedin.com/shareArticle?url=https://mr.schochastics.net/&amp;title=awesome page" target="_blank" class="linkedin"><i class="fa-brands fa-linkedin-in fa-fw fa-lg"></i></a>  <a href="mailto:?subject=awesome page&amp;body=Check out this link:https://mr.schochastics.net/" target="_blank" class="email"><i class="fa-solid fa-envelope fa-fw fa-lg"></i></a><a href="https://www.facebook.com/sharer.php?u=https://mr.schochastics.net/" target="_blank" class="facebook"><i class="fab fa-facebook-f fa-fw fa-lg"></i></a><a href="https://reddit.com/submit?url=https://mr.schochastics.net/&amp;title=awesome page" target="_blank" class="reddit">   <i class="fa-brands fa-reddit-alien fa-fw fa-lg"></i></a></div></div>



</body></html>